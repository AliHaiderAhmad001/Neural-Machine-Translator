{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtxtWv4pARNS"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bKSgofzA1n6"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/NMT\n",
        "!pip install transformers\n",
        "import pathlib\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import unicodedata\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es6dG8iaeHkB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjoMUIa6AJPb",
        "outputId": "27027105-06f9-445f-e93a-59ab45f51688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\n",
            "3423204/3423204 [==============================] - 0s 0us/step\n",
            "/root/.keras/datasets/fra.txt\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n",
        "text_file = tf.keras.utils.get_file(\n",
        "    fname=\"fra-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent/\"fra.txt\"\n",
        "print(text_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sdTvZlCA7YX"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsbOAiQFBBxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ecf19d-3246-4558-a56a-1ff2a0813a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each sample of data will look like this: ('What does he see in her ?', '[start] Que lui trouve-t-il  ?  [end]')\n",
            "Numper of sampels: 167130\n",
            "Max length in english sequences: 51\n",
            "Max length in french sequences: 60\n",
            "Numper of token in english sequences: 16721\n",
            "Numper of token in french sequences: 31405\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def normalize(line):\n",
        "    \"\"\"\n",
        "    Normalize a line of text and split into two at the tab character\n",
        "    Args: The normalize function takes a line of text as input.\n",
        "    Return: Normalized English and French sentences as a tuple (eng, fra).\n",
        "    \"\"\"\n",
        "    line = unicodedata.normalize(\"NFKC\", line.strip())\n",
        "\n",
        "    # Perform regular expression substitutions to add spaces around non-alphanumeric characters\n",
        "    line = re.sub(r\"^([^ \\w])(?!\\s)\", r\"\\1 \", line)\n",
        "    line = re.sub(r\"(\\s[^ \\w])(?!\\s)\", r\"\\1 \", line)\n",
        "    line = re.sub(r\"(?!\\s)([^ \\w])$\", r\" \\1\", line)\n",
        "    line = re.sub(r\"(?!\\s)([^ \\w]\\s)\", r\" \\1\", line)\n",
        "\n",
        "    # Split the line of text into two parts at the tab character\n",
        "    eng, fra = line.split(\"\\t\")\n",
        "\n",
        "    # Add \"[start]\" and \"[end]\" tokens to the \"fra\" part of the line\n",
        "    fra = \"[start] \" + fra + \" [end]\"\n",
        "\n",
        "    # Return the normalized English and French sentences\n",
        "    return eng, fra\n",
        "\n",
        "\n",
        "# normalize each line and separate into English and French\n",
        "with open(text_file) as fp:\n",
        "    text_pairs = [normalize(line) for line in fp]\n",
        "\n",
        "print(f\"Each sample of data will look like this: {text_pairs[55805]}\")\n",
        "print(f\"Numper of sampels: {len(text_pairs)}\")\n",
        "print(f\"Max length in english sequences: {max([len(x[0].split()) for x in text_pairs])}\")\n",
        "print(f\"Max length in french sequences: {max([len(x[1].split()) for x in text_pairs])}\")\n",
        "print(f\"Numper of token in english sequences: {len(set(token for s in [x[0].split() for x in text_pairs] for token in s))}\")\n",
        "print(f\"Numper of token in french sequences: {len(set(token for s in [x[1].split() for x in text_pairs] for token in s))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJBMX3IqCb67",
        "outputId": "45d772a4-c072-4d2b-e946-17838f962fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60 maximum length\n",
            "167130 total pairs\n",
            "116992 training pairs\n",
            "25069 validation pairs\n",
            "25069 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "max_len = max([max([len(x[0].split()), len(x[1].split())]) for x in text_pairs])\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{max_len} maximum length\")\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZkBwvWnIHrz"
      },
      "source": [
        "\n",
        "## Vectorization and Making Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRDKwDIiIJoy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 60\n",
        "        self.source_vocab_size = 14969\n",
        "        self.target_vocab_size = 29219\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# English layer\n",
        "eng_vectorizer = TextVectorization(\n",
        "    max_tokens=config.source_vocab_size,\n",
        "    standardize=None,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length,\n",
        ")\n",
        "# French layer\n",
        "fra_vectorizer = TextVectorization(\n",
        "    max_tokens=config.target_vocab_size,\n",
        "    standardize=None,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length + 1 # since we'll need to offset the sentence by one step during training.\n",
        "\n",
        ")\n",
        "\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_fra_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "# Learn the vocabulary\n",
        "eng_vectorizer.adapt(train_eng_texts)\n",
        "fra_vectorizer.adapt(train_fra_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HG71WIMLXuL"
      },
      "outputs": [],
      "source": [
        "# save for subsequent steps\n",
        "with open(\"vectorize.pickle\", \"wb\") as fp:\n",
        "    data = {\n",
        "        \"train\": train_pairs,\n",
        "        \"val\":   val_pairs,\n",
        "        \"test\":  test_pairs,\n",
        "        \"engvec_config\":  eng_vectorizer.get_config(),\n",
        "        \"engvec_weights\": eng_vectorizer.get_weights(),\n",
        "        \"fravec_config\":  fra_vectorizer.get_config(),\n",
        "        \"fravec_weights\": fra_vectorizer.get_weights(),\n",
        "    }\n",
        "    pickle.dump(data, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yYJmlssBvkA"
      },
      "outputs": [],
      "source": [
        "with open(\"vectorize.pickle\", \"rb\") as fp:\n",
        "    data = pickle.load(fp)\n",
        "\n",
        "train_pairs = data[\"train\"]\n",
        "val_pairs = data[\"val\"]\n",
        "test_pairs = data[\"test\"]   # not used\n",
        "eng_vectorizer = TextVectorization.from_config(data[\"engvec_config\"])\n",
        "eng_vectorizer.set_weights(data[\"engvec_weights\"])\n",
        "fra_vectorizer = TextVectorization.from_config(data[\"fravec_config\"])\n",
        "fra_vectorizer.set_weights(data[\"fravec_weights\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3lj1LCLFta4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.data import AUTOTUNE\n",
        "\n",
        "def format_dataset(eng, fra):\n",
        "    \"\"\"\n",
        "    Formats the dataset by applying vectorization and preparing the inputs for the encoder and decoder.\n",
        "\n",
        "    Args:\n",
        "        eng: English text tensor.\n",
        "        fra: French text tensor.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of formatted inputs for the encoder and decoder.\n",
        "    \"\"\"\n",
        "    eng = eng_vectorizer(eng)\n",
        "    fra = fra_vectorizer(fra)\n",
        "    return (\n",
        "        {\"encoder_inputs\": eng, \"decoder_inputs\": fra[:, :-1]},\n",
        "        fra[:, 1:]\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs, batch_size=64):\n",
        "    \"\"\"\n",
        "    Creates a dataset from pairs of English and French texts.\n",
        "\n",
        "    Args:\n",
        "        pairs: List of pairs containing English and French texts.\n",
        "        batch_size: Batch size for the dataset.\n",
        "\n",
        "    Returns:\n",
        "        Formatted and preprocessed dataset.\n",
        "    \"\"\"\n",
        "    eng_texts, fra_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    fra_texts = list(fra_texts)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fra_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(2048).prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plQuKWBfJas8"
      },
      "source": [
        "## Transformer Building Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teVoKbyGbzyu"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz42CtYkbuT8"
      },
      "source": [
        "#### Sinu_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt1Tv9RQbnl8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class SinusoidalPositionalEncoding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    SinusoidalPositionalEncoding layer.\n",
        "\n",
        "    This layer applies sinusoidal positional encodings to the input embeddings.\n",
        "\n",
        "    Args:\n",
        "        config (object): Configuration object containing parameters.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, name = None, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the SinusoidalPositionalEncoding layer.\n",
        "\n",
        "        Args:\n",
        "            config (object): Configuration object with parameters for positional encoding.\n",
        "        \"\"\"\n",
        "        super(SinusoidalPositionalEncoding, self).__init__(name = name)\n",
        "        super(SinusoidalPositionalEncoding, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input_ids):\n",
        "        \"\"\"\n",
        "        Apply positional encodings to the input embeddings.\n",
        "\n",
        "        Args:\n",
        "            input_ids (tf.Tensor): Input tensor containing token IDs.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor with positional encodings added.\n",
        "        \"\"\"\n",
        "        self.position_encoding = self.create_positional_encoding_matrix(\n",
        "                input_ids.shape[1], config.hidden_size, config.frequency_factor\n",
        "        )\n",
        "        return self.position_encoding\n",
        "\n",
        "    def create_positional_encoding_matrix(self, sequence_length, embedding_dimension, frequency_factor=10000):\n",
        "        \"\"\"\n",
        "        Create a positional encoding matrix.\n",
        "\n",
        "        Args:\n",
        "            sequence_length (int): Length of the input sequence.\n",
        "            embedding_dimension (int): Dimensionality of the positional embeddings. Must be an even integer.\n",
        "            frequency_factor (int): Constant for the sinusoidal functions.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Matrix of positional embeddings of shape (sequence_length, embedding_dimension).\n",
        "            The value at element (k, 2i) is sin(k / frequency_factor^(2i / embedding_dimension)),\n",
        "            and the value at element (k, 2i+1) is cos(k / frequency_factor^(2i / embedding_dimension)).\n",
        "        \"\"\"\n",
        "        assert embedding_dimension % 2 == 0, \"Embedding dimension needs to be an even integer\"\n",
        "        embedding_dimension_half = embedding_dimension // 2\n",
        "        positions = tf.range(sequence_length, dtype=tf.float32)[:, tf.newaxis]  # Column vector of shape (sequence_length, 1)\n",
        "        frequency_indices = tf.range(embedding_dimension_half, dtype=tf.float32)[tf.newaxis, :]  # Row vector of shape (1, embedding_dimension/2)\n",
        "        frequency_denominator = tf.pow(frequency_factor, -frequency_indices / embedding_dimension_half)  # frequency_factor^(-2i/d)\n",
        "        frequency_arguments = positions / frequency_denominator  # Matrix of shape (sequence_length, embedding_dimension)\n",
        "        sin_values = tf.sin(frequency_arguments)\n",
        "        cos_values = tf.cos(frequency_arguments)\n",
        "        positional_encodings = tf.concat([sin_values, cos_values], axis=1)\n",
        "\n",
        "        return positional_encodings\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Get the configuration of the SinusoidalPositionalEncoding layer.\n",
        "\n",
        "        Returns:\n",
        "            dict: Configuration dictionary.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbDvfmb0nOtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f19f3f-c44f-4950-fe6d-d5b51cd2895f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            "tf.Tensor([[3 2 2 3]], shape=(1, 4), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 0.          0.          1.          1.        ]\n",
            " [ 0.841471   -0.5063722   0.5403023   0.862315  ]\n",
            " [ 0.90929747 -0.8733047  -0.4161468   0.48717433]\n",
            " [ 0.14112    -0.99975514 -0.9899925  -0.02212713]], shape=(4, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Define the configuration\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 4\n",
        "        self.source_vocab_size = 14969\n",
        "        self.target_vocab_size = 29219\n",
        "        self.hidden_size = 4\n",
        "        self.frequency_factor = 10000\n",
        "        self.mask_zero = True\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create an instance of the SinusoidalPositionalEncoding layer\n",
        "positional_encoding_layer = SinusoidalPositionalEncoding(config)\n",
        "\n",
        "# Create a sample input tensor with token IDs\n",
        "batch_size = 1\n",
        "seq_length = 4\n",
        "input_ids = tf.random.uniform((batch_size, seq_length), maxval=config.sequence_length, dtype=tf.int32)\n",
        "\n",
        "# Apply positional encodings\n",
        "output_embeddings = positional_encoding_layer(input_ids)\n",
        "\n",
        "# Print the output positional embeddings\n",
        "print(\"Outputs:\")\n",
        "print(input_ids)\n",
        "print(output_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MJkW6JgnkcX"
      },
      "source": [
        "#### Pos_Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6nWd8WdPFOf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class PositionalEmbeddings(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    PositionalEmbeddings layer.\n",
        "\n",
        "    This layer generates positional embeddings based on input IDs.\n",
        "    It uses an Embedding layer to map position IDs to position embeddings.\n",
        "\n",
        "    Args:\n",
        "        config (object): Configuration object containing parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, name = None, **kwargs):\n",
        "        super(PositionalEmbeddings, self).__init__(name = name)\n",
        "        super(PositionalEmbeddings, self).__init__(**kwargs)\n",
        "        self.positional_embeddings = tf.keras.layers.Embedding(\n",
        "            input_dim=config.sequence_length, output_dim=config.hidden_size\n",
        "        )\n",
        "\n",
        "    def call(self, input_ids):\n",
        "        \"\"\"\n",
        "        Generate positional embeddings.\n",
        "\n",
        "        Args:\n",
        "            input_ids (tf.Tensor): Input tensor containing token IDs.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Positional embeddings tensor of shape (batch_size, seq_length, hidden_size).\n",
        "        \"\"\"\n",
        "        seq_length = input_ids.shape[1]\n",
        "        position_ids = tf.range(seq_length, dtype=tf.int32)[tf.newaxis, :]\n",
        "        position_embeddings = self.positional_embeddings(position_ids)\n",
        "        return position_embeddings\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Get the layer configuration.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing the layer configuration.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"positional_embeddings\": self.positional_embeddings,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-kEgJbVzlcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39231afc-5f1a-4fa4-dcda-14bec6bcf569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            "tf.Tensor(\n",
            "[[[ 0.01630845 -0.0280382  -0.01342707  0.00249801]\n",
            "  [ 0.01012968 -0.00064945 -0.02948507  0.02167038]\n",
            "  [-0.04061853  0.03396517  0.02463391 -0.00579173]\n",
            "  [-0.01580817 -0.03685774 -0.01101297  0.0341831 ]]], shape=(1, 4, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Define the configuration\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 4\n",
        "        self.source_vocab_size = 14969\n",
        "        self.target_vocab_size = 29219\n",
        "        self.hidden_size = 4\n",
        "        self.frequency_factor = 10000\n",
        "        self.max_position_embeddings = 4\n",
        "        self.mask_zero = True\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create an instance of the PositionalEmbeddings layer\n",
        "positional_encoding_layer = PositionalEmbeddings(config)\n",
        "\n",
        "# Create a sample input tensor with token IDs\n",
        "batch_size = 1\n",
        "seq_length = 4\n",
        "input_ids = tf.random.uniform((batch_size, seq_length), maxval=config.sequence_length, dtype=tf.int32)\n",
        "\n",
        "# Apply positional encodings\n",
        "output_embeddings = positional_encoding_layer(input_ids)\n",
        "\n",
        "# Print the output positional embeddings\n",
        "print(\"Outputs:\")\n",
        "print(output_embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn2AC0H1yKdX"
      },
      "source": [
        "#### Embeddings layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ss3WhIL_iOv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Embeddings(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Embeddings layer.\n",
        "\n",
        "    This layer combines token embeddings with positional embeddings to create the final embeddings.\n",
        "\n",
        "    Args:\n",
        "        config (object): Configuration object containing parameters.\n",
        "        vocab_size: Vocabulary size.\n",
        "\n",
        "    Attributes:\n",
        "        token_embeddings (tf.keras.layers.Embedding): Token embedding layer.\n",
        "        PositionalInfo (tf.keras.layers.Layer): Positional information layer.\n",
        "        dropout (tf.keras.layers.Dropout): Dropout layer for regularization.\n",
        "        norm (tf.keras.layers.LayerNormalization): Layer normalization for normalization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, vocab_size, name = None,  **kwargs):\n",
        "        super(Embeddings, self).__init__(name = name)\n",
        "        super(Embeddings, self).__init__(**kwargs)\n",
        "        self.token_embeddings = tf.keras.layers.Embedding(\n",
        "            input_dim= vocab_size, output_dim=config.hidden_size\n",
        "        )\n",
        "        if config.positional_information_type == 'embs':\n",
        "            self.PositionalInfo = PositionalEmbeddings(config)\n",
        "        elif config.positional_information_type == 'sinu':\n",
        "            self.PositionalInfo = SinusoidalPositionalEncoding(config)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
        "        self.norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, input_ids, training=False):\n",
        "        \"\"\"\n",
        "        Generate embeddings for input IDs.\n",
        "\n",
        "        Args:\n",
        "            input_ids (tf.Tensor): Input tensor containing token IDs.\n",
        "            training (bool, optional): Whether the model is in training mode. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Embeddings tensor of shape (batch_size, seq_length, hidden_size).\n",
        "        \"\"\"\n",
        "        positional_info = self.PositionalInfo(input_ids)\n",
        "        x = self.token_embeddings(input_ids)\n",
        "        x += positional_info\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        return x\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        \"\"\"\n",
        "        Computes the mask for the inputs.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): Input tensor.\n",
        "            mask (tf.Tensor, optional): Mask tensor. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Computed mask tensor.\n",
        "        \"\"\"\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Get the layer configuration.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing the layer configuration.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"token_embeddings\": self.token_embeddings,\n",
        "            \"PositionalInfo\": self.PositionalInfo,\n",
        "            \"dropout\": self.dropout,\n",
        "            \"norm\": self.norm,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwv2m4PzRJm8"
      },
      "outputs": [],
      "source": [
        "# Define the configuration\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 4\n",
        "        self.source_vocab_size = 14969\n",
        "        self.target_vocab_size = 29219\n",
        "        self.hidden_size = 4\n",
        "        self.frequency_factor = 10000\n",
        "        self.max_position_embeddings = 4\n",
        "        self.positional_information_type = 'embs'\n",
        "        self.source_vocab_size = 10\n",
        "        self.target_vocab_size = 10\n",
        "        self.hidden_dropout_prob = 0.1\n",
        "\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create an instance of the Embeddings layer\n",
        "Embeddings_layer = Embeddings(config, vocab_size = 10)\n",
        "\n",
        "# Create a sample input tensor with token IDs\n",
        "batch_size = 1\n",
        "seq_length = 4\n",
        "input_ids = tf.random.uniform((batch_size, seq_length), maxval=config.sequence_length, dtype=tf.int32)\n",
        "\n",
        "# Apply positional encodings\n",
        "output_embeddings = Embeddings_layer(input_ids)\n",
        "\n",
        "# Print the output positional embeddings\n",
        "print(\"Outputs:\")\n",
        "print(output_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuBIvpAXGiSf"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xpcf7AWHtUq"
      },
      "source": [
        "#### Attination Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHyzu3wRuHqr"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention head implementation.\n",
        "\n",
        "    Args:\n",
        "        head_dim: Dimensionality of the attention head.\n",
        "\n",
        "    Attributes:\n",
        "        head_dim: Dimensionality of the attention head.\n",
        "        query_weights: Dense layer for query projection.\n",
        "        key_weights: Dense layer for key projection.\n",
        "        value_weights: Dense layer for value projection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, head_dim, name = None, **kwargs):\n",
        "        super(AttentionHead, self).__init__(name = name)\n",
        "        super(AttentionHead, self).__init__(**kwargs)\n",
        "        self.supports_masking = True  # Enable masking support\n",
        "        self.head_dim = head_dim\n",
        "        self.query_weights = tf.keras.layers.Dense(head_dim)\n",
        "        self.key_weights = tf.keras.layers.Dense(head_dim)\n",
        "        self.value_weights = tf.keras.layers.Dense(head_dim)\n",
        "\n",
        "    def call(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        Applies attention mechanism to the input query, key, and value tensors.\n",
        "\n",
        "        Args:\n",
        "            query: Query tensor.\n",
        "            key: Key tensor.\n",
        "            value: Value tensor.\n",
        "            mask: Optional mask tensor.\n",
        "\n",
        "        Returns:\n",
        "            Updated value embeddings after applying attention mechanism.\n",
        "        \"\"\"\n",
        "        query = self.query_weights(query)\n",
        "        key = self.key_weights(key)\n",
        "        value = self.value_weights(value)\n",
        "\n",
        "        att_scores = tf.matmul(query, tf.transpose(key, perm=[0, 2, 1])) / tf.math.sqrt(tf.cast(tf.shape(query)[-1], tf.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, dtype=tf.bool)\n",
        "            att_scores = tf.where(mask, att_scores, tf.constant(-1e9, dtype=att_scores.dtype))\n",
        "\n",
        "        att_weights = tf.nn.softmax(att_scores, axis=-1)\n",
        "        n_value = tf.matmul(att_weights, value)\n",
        "\n",
        "        return n_value\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the attention head layer.\n",
        "\n",
        "        Returns:\n",
        "            Configuration dictionary.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"head_dim\": self.head_dim,\n",
        "            \"query_weights\": self.query_weights,\n",
        "            \"key_weights\": self.key_weights,\n",
        "            \"value_weights\": self.value_weights,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F74CdsjAHyez"
      },
      "source": [
        "#### Multi-head attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqGoyesAHqR1"
      },
      "outputs": [],
      "source": [
        "class MultiHead_Attention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Multi-head attention layer implementation.\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing hyperparameters.\n",
        "\n",
        "    Attributes:\n",
        "        supports_masking: Boolean indicating if the layer supports masking.\n",
        "        hidden_size: Dimensionality of the hidden state.\n",
        "        num_heads: Number of attention heads.\n",
        "        head_dim: Dimensionality of each attention head.\n",
        "        attention_heads: List of AttentionHead layers.\n",
        "        fc: Fully connected layer for final projection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, name=None, **kwargs):\n",
        "        super(MultiHead_Attention, self).__init__(name=name)\n",
        "        super(MultiHead_Attention, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.num_heads = config.num_heads\n",
        "        self.head_dim = config.hidden_size // config.num_heads\n",
        "        self.attention_heads = [AttentionHead(self.head_dim) for _ in range(self.num_heads)]\n",
        "        self.fc = tf.keras.layers.Dense(config.hidden_size)\n",
        "\n",
        "    def call(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        Applies multi-head attention mechanism to the input query, key, and value tensors.\n",
        "\n",
        "        Args:\n",
        "            query: Query tensor.\n",
        "            key: Key tensor.\n",
        "            value: Value tensor.\n",
        "            mask: Optional mask tensor.\n",
        "\n",
        "        Returns:\n",
        "            Updated hidden state after applying multi-head attention mechanism.\n",
        "        \"\"\"\n",
        "        attention_outputs = [attention_head(query, key, value, mask=mask) for attention_head in self.attention_heads]\n",
        "        hidden_state = tf.concat(attention_outputs, axis=-1)\n",
        "        hidden_state = self.fc(hidden_state)\n",
        "        return hidden_state\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the multi-head attention layer.\n",
        "\n",
        "        Returns:\n",
        "            Configuration dictionary.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"head_dim\": self.head_dim,\n",
        "            \"attention_heads\": self.attention_heads,\n",
        "            \"fc\": self.fc,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kf58zACgZIS",
        "outputId": "5f5b07a0-58bc-4aa0-b617-52f9d923a506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            "tf.Tensor(\n",
            "[[[-0.19603872  0.62370175  0.00938863 -0.8792861 ]\n",
            "  [-0.19392842  0.6028574   0.00985217 -0.895087  ]\n",
            "  [-0.19179727  0.6012584   0.0114027  -0.89725673]\n",
            "  [-0.19112027  0.59981096  0.01184295 -0.89861196]]], shape=(1, 4, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Define the configuration\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 4\n",
        "        self.source_vocab_size = 10\n",
        "        self.target_vocab_size = 10\n",
        "        self.hidden_size = 4\n",
        "        self.frequency_factor = 10000\n",
        "        self.max_position_embeddings = 4\n",
        "        self.positional_information_type = 'embs'\n",
        "        self.hidden_dropout_prob = 0.1\n",
        "        self.num_heads = 2\n",
        "\n",
        "config = Config()\n",
        "\n",
        "Embeddings_layer = Embeddings(config, 10)\n",
        "\n",
        "input_ids = tf.constant([[2, 2, 0, 0]])\n",
        "\n",
        "x = Embeddings_layer(input_ids)\n",
        "\n",
        "# Apply MultiHeadAttention\n",
        "multihead_attn = MultiHead_Attention(config)\n",
        "x = multihead_attn(x, x, x)\n",
        "\n",
        "print(\"Outputs:\")\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo50vujWTDwq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg_-qfdCHIxR"
      },
      "source": [
        "#### The Feed-Forward Layer and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMUgHrVcHLVW"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Feed-forward layer implementation.\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing hyperparameters.\n",
        "\n",
        "    Attributes:\n",
        "        supports_masking: Boolean indicating if the layer supports masking.\n",
        "        fc1: First dense layer.\n",
        "        fc2: Second dense layer.\n",
        "        dropout: Dropout layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, name=None, **kwargs):\n",
        "        super(FeedForward, self).__init__(name=name)\n",
        "        super(FeedForward, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.fc1 = tf.keras.layers.Dense(config.intermediate_fc_size, activation=tf.keras.activations.gelu)\n",
        "        self.fc2 = tf.keras.layers.Dense(config.hidden_size)\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def call(self, hidden_state, training=False):\n",
        "        \"\"\"\n",
        "        Applies feed-forward transformation to the input hidden state.\n",
        "\n",
        "        Args:\n",
        "            hidden_state: Hidden state tensor (batch_size, sequence_length, hidden_size).\n",
        "            training: Boolean indicating whether the model is in training mode or inference mode.\n",
        "\n",
        "        Returns:\n",
        "            Updated hidden state after applying feed-forward transformation.\n",
        "        \"\"\"\n",
        "        hidden_state = self.fc1(hidden_state)\n",
        "        hidden_state = self.dropout(hidden_state, training=training)\n",
        "        hidden_state = self.fc2(hidden_state)\n",
        "        return hidden_state\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the feed-forward layer.\n",
        "\n",
        "        Returns:\n",
        "            Configuration dictionary.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"fc1\": self.fc1,\n",
        "            \"fc2\": self.fc2,\n",
        "            \"dropout\": self.dropout,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGU0kMOzHaAj"
      },
      "source": [
        "#### Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKDAMyvuHYil"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Encoder layer implementation.\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object.\n",
        "\n",
        "    Attributes:\n",
        "        multihead_attention: Multi-head attention layer.\n",
        "        norm1: Layer normalization layer.\n",
        "        norm2: Layer normalization layer.\n",
        "        feed_forward: Feed-forward layer.\n",
        "        dropout: Dropout layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, name=None, **kwargs):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.multihead_attention = MultiHead_Attention(config)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
        "        self.feed_forward = FeedForward(config)\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def call(self, hidden_state, mask=None, training=False):\n",
        "        \"\"\"\n",
        "        Applies the encoder layer to the input hidden state.\n",
        "\n",
        "        Args:\n",
        "            hidden_state: Hidden state tensor (bs, len, dim).\n",
        "            mask: Padding mask tensor (bs, len, len) or (bs, 1, len) or None.\n",
        "            training: Boolean flag indicating whether the layer is in training mode or not.\n",
        "\n",
        "        Returns:\n",
        "            Updated hidden state after applying the encoder layer.\n",
        "        \"\"\"\n",
        "\n",
        "        attention_output = self.multihead_attention(hidden_state, hidden_state, hidden_state, mask = None)  # Apply multi-head attention\n",
        "        hidden_state = self.norm1(attention_output + hidden_state)  # Add skip connection and normalize\n",
        "        feed_forward_output = self.feed_forward(hidden_state)  # Apply feed-forward layer\n",
        "        hidden_state = self.norm2(feed_forward_output + hidden_state)  # Add skip connection and normalize\n",
        "        hidden_state = self.dropout(hidden_state, training=training)  # Apply dropout\n",
        "        return hidden_state\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the encoder layer.\n",
        "\n",
        "        Returns:\n",
        "            Configuration dictionary.\n",
        "        \"\"\"\n",
        "\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"multihead_attention\": self.multihead_attention,\n",
        "            \"norm1\": self.norm1,\n",
        "            \"norm2\": self.norm2,\n",
        "            \"feed_forward\": self.feed_forward,\n",
        "            \"dropout\": self.dropout,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka3QTSmMH54q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403d0798-f32c-4be9-a8e7-d33c9f74392b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            "tf.Tensor(\n",
            "[[[ 1.3782277  -0.27358374  0.28824583 -1.3928899 ]\n",
            "  [-0.58701557  1.6332425  -0.05553263 -0.9906943 ]\n",
            "  [ 0.7772341  -1.6541214   0.06944932  0.80743796]\n",
            "  [ 1.2515924  -1.2637957   0.6517466  -0.63954335]]\n",
            "\n",
            " [[ 1.3063093   0.23750131 -0.04989911 -1.4939115 ]\n",
            "  [-0.65859026  1.619962    0.00743284 -0.96880454]\n",
            "  [-0.9060655   1.4495562   0.4089052  -0.95239586]\n",
            "  [ 1.1702925  -1.542554    0.48513612 -0.11287448]]], shape=(2, 4, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Define the configuration\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 4\n",
        "        self.source_vocab_size = 10\n",
        "        self.target_vocab_size = 10\n",
        "        self.hidden_size = 4\n",
        "        self.frequency_factor = 10000\n",
        "        self.max_position_embeddings = 4\n",
        "        self.positional_information_type = 'embs'\n",
        "        self.hidden_dropout_prob = 0.1\n",
        "        self.num_heads = 2\n",
        "        self.intermediate_fc_size = self.hidden_size * 4.\n",
        "\n",
        "\n",
        "config = Config()\n",
        "\n",
        "Embeddings_layer = Embeddings(config, 10)\n",
        "\n",
        "batch_size = 2\n",
        "seq_length = 4\n",
        "input_ids = tf.random.uniform((batch_size, seq_length), maxval=config.sequence_length, dtype=tf.int32)\n",
        "\n",
        "x = Embeddings_layer(input_ids)\n",
        "\n",
        "encoder = Encoder(config)\n",
        "x = encoder(x)\n",
        "\n",
        "print(\"Outputs:\")\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rCuO7eeH6pE"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohnhzncjhZzE"
      },
      "source": [
        "#### Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoEUlfzplo-u"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Decoder layer implementation.\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing hyperparameters.\n",
        "\n",
        "    Attributes:\n",
        "        supports_masking: Boolean indicating if the layer supports masking.\n",
        "        masked_multihead_attention: Masked multi-head attention layer.\n",
        "        multihead_attention: Multi-head attention layer.\n",
        "        norm1: Layer normalization layer.\n",
        "        norm2: Layer normalization layer.\n",
        "        norm3: Layer normalization layer.\n",
        "        feed_forward: Feed-forward layer.\n",
        "        dropout: Dropout layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, name=None, **kwargs):\n",
        "        super(Decoder, self).__init__(name=name)\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.masked_multihead_attention = MultiHead_Attention(config)\n",
        "        self.multihead_attention = MultiHead_Attention(config)\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm3 = tf.keras.layers.LayerNormalization()\n",
        "        self.feed_forward = FeedForward(config)\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def call(self, hidden_state, encoder_info, mask=None, training=False):\n",
        "        \"\"\"\n",
        "        Applies the decoder layer to the input hidden state.\n",
        "\n",
        "        Args:\n",
        "            hidden_state: Hidden state tensor.\n",
        "            encoder_info: Encoder information tensor.\n",
        "            mask: Optional mask tensor.\n",
        "            training: Boolean indicating if the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "            Updated hidden state after applying the decoder layer.\n",
        "        \"\"\"\n",
        "        input_shape = tf.shape(hidden_state)\n",
        "        causal_mask = self.get_causal_attention_mask(hidden_state)\n",
        "\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.int32)\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output = self.masked_multihead_attention(hidden_state, hidden_state, hidden_state, mask=causal_mask)\n",
        "        hidden_state = self.norm1(attention_output + hidden_state)\n",
        "        attention_output = self.multihead_attention(hidden_state, encoder_info, encoder_info, mask=padding_mask)\n",
        "        hidden_state = self.norm2(attention_output + hidden_state)\n",
        "        feed_forward_output = self.feed_forward(hidden_state)\n",
        "        hidden_state = self.norm3(feed_forward_output + hidden_state)\n",
        "        hidden_state = self.dropout(hidden_state, training=training)\n",
        "        return hidden_state\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        \"\"\"\n",
        "        Generates the causal attention mask.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            Causal attention mask tensor.\n",
        "        \"\"\"\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=tf.int32)\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the decoder layer.\n",
        "\n",
        "        Returns:\n",
        "            Configuration dictionary.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"masked_multihead_attention\": self.masked_multihead_attention,\n",
        "            \"multihead_attention\": self.multihead_attention,\n",
        "            \"norm1\": self.norm1,\n",
        "            \"norm2\": self.norm2,\n",
        "            \"norm3\": self.norm3,\n",
        "            \"feed_forward\": self.feed_forward,\n",
        "            \"dropout\": self.dropout,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPKzdeVbM4k1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuIekwIgpMTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e250713e-446a-4a90-d3fd-22b78de75e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            "tf.Tensor(\n",
            "[[[ 0.7623217  -0.71306705 -1.2300535   1.1807988 ]\n",
            "  [ 1.250659   -0.643796    0.65204614 -1.258909  ]\n",
            "  [ 1.1821826  -0.06859311  0.43531924 -1.5489087 ]\n",
            "  [ 1.1212182  -0.24643904  0.6328109  -1.5075902 ]]\n",
            "\n",
            " [[ 0.58930755 -0.15254109 -1.5472996   1.1105332 ]\n",
            "  [ 1.3379257  -1.3227949   0.4647567  -0.4798876 ]\n",
            "  [ 0.57029516 -0.7739589   1.336633   -1.1329693 ]\n",
            "  [ 0.4329416  -0.86517     1.4338249  -1.0015966 ]]], shape=(2, 4, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 4\n",
        "        self.source_vocab_size = 10\n",
        "        self.target_vocab_size = 10\n",
        "        self.hidden_size = 4\n",
        "        self.frequency_factor = 10000\n",
        "        self.max_position_embeddings = 4\n",
        "        self.positional_information_type = 'embs'\n",
        "        self.hidden_dropout_prob = 0.1\n",
        "        self.num_heads = 2\n",
        "        self.intermediate_fc_size = self.hidden_size * 4\n",
        "\n",
        "config = Config()\n",
        "\n",
        "embeddings_layer1 = Embeddings(config, 10)\n",
        "embeddings_layer2 = Embeddings(config, 10)\n",
        "\n",
        "batch_size = 2\n",
        "seq_length = 4\n",
        "input_ids1 = tf.constant([[2, 1, 3, 0], [2, 1, 3, 0]])\n",
        "input_ids2 = tf.constant([[1, 3, 0, 0], [2, 1, 3, 0]])\n",
        "\n",
        "x1 = embeddings_layer1(input_ids1)\n",
        "x2 = embeddings_layer2(input_ids2)\n",
        "\n",
        "encoder = Encoder(config)\n",
        "decoder = Decoder(config)\n",
        "\n",
        "enc_out = encoder(x1)\n",
        "enc_out = tf.keras.layers.Masking()(enc_out)\n",
        "\n",
        "x = decoder(x2, enc_out)\n",
        "\n",
        "print(\"Outputs:\")\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEj1JqyOwlyq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Transformer model implementation for sequence-to-sequence tasks.\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing model hyperparameters.\n",
        "        source_vocab_size: The vocabulary size of the source language.\n",
        "        target_vocab_size: The vocabulary size of the target language.\n",
        "\n",
        "    Attributes:\n",
        "        enc_embed_layer: Embeddings layer for the encoder inputs.\n",
        "        dec_embed_layer: Embeddings layer for the decoder inputs.\n",
        "        encoder: List of encoder layers.\n",
        "        decoder: List of decoder layers.\n",
        "        dropout: Dropout layer for regularization.\n",
        "        output_layer: Dense layer for output prediction.\n",
        "\n",
        "    Methods:\n",
        "        call: Forward pass of the transformer model.\n",
        "        get_config: Returns the configuration dictionary of the transformer model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, source_vocab_size, target_vocab_size, name=None, **kwargs):\n",
        "        super(Transformer, self).__init__(name=name)\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "        self.enc_embed_layer = Embeddings(config, source_vocab_size)\n",
        "        self.dec_embed_layer = Embeddings(config, target_vocab_size)\n",
        "        self.encoder = [Encoder(config) for _ in range(config.num_blocks)]\n",
        "        self.decoder = [Decoder(config) for _ in range(config.num_blocks)]\n",
        "        self.dropout = tf.keras.layers.Dropout(config.final_dropout_prob)\n",
        "        self.output_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass of the transformer model.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input data.\n",
        "            training: Boolean flag indicating whether the model is in training mode or not.\n",
        "\n",
        "        Returns:\n",
        "            Output logits of the transformer model.\n",
        "        \"\"\"\n",
        "        source_inputs = inputs[\"encoder_inputs\"]\n",
        "        target_inputs = inputs[\"decoder_inputs\"]\n",
        "\n",
        "        x_enc = self.enc_embed_layer(source_inputs)\n",
        "        x_dec = self.dec_embed_layer(target_inputs)\n",
        "\n",
        "        for encoder_layer in self.encoder:\n",
        "            x_enc = encoder_layer(x_enc, training=training)\n",
        "\n",
        "        # Remove the mask used in the encoder as it's not needed in the decoder\n",
        "        x_enc._keras_mask = None\n",
        "\n",
        "        for decoder_layer in self.decoder:\n",
        "            x_dec = decoder_layer(x_dec, x_enc, training=training)\n",
        "\n",
        "        x_dec = self.dropout(x_dec, training=training)\n",
        "        x_logits = self.output_layer(x_dec)\n",
        "\n",
        "        # Remove the mask from the logits as it's not needed in the loss function\n",
        "        x_logits._keras_mask = None\n",
        "\n",
        "        return x_logits\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration dictionary of the transformer model.\n",
        "\n",
        "        Returns:\n",
        "            Configuration dictionary.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"enc_embed_layer\": self.enc_embed_layer,\n",
        "            \"dec_embed_layer\": self.dec_embed_layer,\n",
        "            \"encoder\": self.encoder,\n",
        "            \"decoder\": self.decoder,\n",
        "            \"dropout\": self.dropout,\n",
        "            \"encoder\": self.encoder,\n",
        "            \"decoder\": self.decoder,\n",
        "            \"output_layer\": self.output_layer,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV-5AC16T3pv"
      },
      "source": [
        "## End-to-end Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSGsKq5u3uDE"
      },
      "source": [
        "### LrSchedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jPMdR2gT7OT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class LrSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"\n",
        "    Custom learning rate schedule with warmup for training.\n",
        "\n",
        "    Args:\n",
        "        hidden_size: Hidden size of the model.\n",
        "        warmup_steps: Number of warmup steps for learning rate warmup.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, warmup_steps=4000):\n",
        "        super(LrSchedule, self).__init__()\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.d = tf.cast(hidden_size, tf.float32)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        \"\"\"\n",
        "        Calculates the learning rate based on the current step.\n",
        "\n",
        "        Args:\n",
        "            step: Current optimization step.\n",
        "\n",
        "        Returns:\n",
        "            The learning rate value.\n",
        "\n",
        "        \"\"\"\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        lr = tf.math.rsqrt(self.d) * tf.math.minimum(arg1, arg2)\n",
        "        return lr\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the custom learning rate schedule.\n",
        "\n",
        "        Returns:\n",
        "            Configuration dictionary.\n",
        "\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"warmup_steps\": self.warmup_steps,\n",
        "            \"hidden_size\": int(self.d.numpy()),  # Cast to native Python int\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "EdTxp0TthBw3",
        "outputId": "55911e20-e0e6-497a-9d67-663eb0971fe0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.sequence_length = 4\n",
        "        self.source_vocab_size = 10\n",
        "        self.target_vocab_size = 10\n",
        "        self.hidden_size = 4\n",
        "        self.frequency_factor = 10000\n",
        "        self.max_position_embeddings = 4\n",
        "        self.positional_information_type = 'embs'\n",
        "        self.hidden_dropout_prob = 0.1\n",
        "        self.num_heads = 2\n",
        "        self.intermediate_fc_size = self.hidden_size * 4\n",
        "        self.warmup_steps = 4000\n",
        "\n",
        "\n",
        "config = Config()\n",
        "\n",
        "d = 768\n",
        "lr = LrSchedule()\n",
        "optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "plt.plot(lr(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks43_OTo3z_b"
      },
      "source": [
        "### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdJaX55idYRC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def scce_masked_loss(label, pred):\n",
        "    \"\"\"\n",
        "    Computes the masked Sparse Categorical Cross Entropy (SCCE) loss between the predicted and target labels.\n",
        "\n",
        "    Args:\n",
        "        label: Target label tensor.\n",
        "        pred: Predicted logit tensor.\n",
        "\n",
        "    Returns:\n",
        "        Masked loss value.\n",
        "    \"\"\"\n",
        "    # Create a mask to ignore padded tokens\n",
        "    mask = label != 0\n",
        "\n",
        "    # Use Sparse Categorical Cross Entropy loss with no reduction\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "    # Compute the loss without reducing, which will return a loss value for each token\n",
        "    loss = loss_object(label, pred)\n",
        "\n",
        "    # Apply the mask to ignore padded tokens in the loss calculation\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Compute the average loss over non-padded tokens\n",
        "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUbvzlUa3rnQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def cce_loss(label, pred):\n",
        "    \"\"\"\n",
        "    Computes the Categorical Cross Entropy (CCE) loss with optional label smoothing.\n",
        "\n",
        "    Args:\n",
        "        label: Target label tensor.\n",
        "        pred: Predicted logit tensor.\n",
        "\n",
        "    Returns:\n",
        "        Computed CCE loss value.\n",
        "    \"\"\"\n",
        "    # Create a mask to ignore padded tokens\n",
        "    mask = label != 0\n",
        "\n",
        "    # Use Categorical Cross Entropy with optional label smoothing\n",
        "    scc_loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "        from_logits=True, label_smoothing=0.1, reduction='none')\n",
        "\n",
        "    # Convert label to one-hot encoding\n",
        "    label = tf.one_hot(tf.cast(label, tf.int32), config.target_vocab_size)\n",
        "\n",
        "    # Compute the loss with the label smoothing\n",
        "    loss = scc_loss(label, pred)\n",
        "\n",
        "    # Apply the mask to ignore padded tokens in the loss calculation\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Compute the average loss over non-padded tokens\n",
        "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2cGZ_is33Yv"
      },
      "source": [
        "### Metrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSx8rS3_3oKY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "    \"\"\"\n",
        "    Computes the masked accuracy between the predicted and target labels.\n",
        "\n",
        "    Args:\n",
        "        label: Target label tensor.\n",
        "        pred: Predicted label tensor.\n",
        "\n",
        "    Returns:\n",
        "        Masked accuracy value.\n",
        "    \"\"\"\n",
        "    # Get the predicted labels by taking the argmax along the last dimension\n",
        "    pred_labels = tf.argmax(pred, axis=2)\n",
        "\n",
        "    # Convert the target labels to the same data type as the predicted labels\n",
        "    label = tf.cast(label, pred_labels.dtype)\n",
        "\n",
        "    # Compute a binary tensor for matching predicted and target labels\n",
        "    match = label == pred_labels\n",
        "\n",
        "    # Create a mask to ignore padded tokens\n",
        "    mask = label != 0\n",
        "\n",
        "    # Apply the mask to the matching tensor\n",
        "    match = match & mask\n",
        "\n",
        "    # Convert the binary tensor to floating-point values\n",
        "    match = tf.cast(match, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "\n",
        "    # Compute the accuracy over non-padded tokens\n",
        "    return tf.reduce_sum(match) / tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IlvL3qo5bMi",
        "outputId": "e9f6e30b-fd8a-481e-97f5-9d15b63b15c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: [0.7860753]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def compute_precision(candidate_ngrams, reference_ngrams):\n",
        "    \"\"\"\n",
        "    Compute the precision of candidate n-grams with respect to reference n-grams.\n",
        "\n",
        "    Args:\n",
        "        candidate_ngrams: List of tuples representing candidate n-grams.\n",
        "        reference_ngrams: List of tuples representing reference n-grams.\n",
        "\n",
        "    Returns:\n",
        "        Precision value.\n",
        "    \"\"\"\n",
        "    candidate_counter = Counter(candidate_ngrams)\n",
        "    reference_counter = Counter(reference_ngrams)\n",
        "\n",
        "    # Calculate the intersection of n-grams in candidate and reference sentences\n",
        "    intersection = sum((candidate_counter & reference_counter).values())\n",
        "\n",
        "    # Total candidate n-grams\n",
        "    total_candidate = sum(candidate_counter.values())\n",
        "\n",
        "    # To avoid division by zero, set precision to a small value if there are no candidate n-grams\n",
        "    precision = intersection / total_candidate if total_candidate > 0 else 1e-10\n",
        "\n",
        "    return precision\n",
        "\n",
        "def compute_bleu_batch(references_batch, candidates_batch, max_n=4):\n",
        "    \"\"\"\n",
        "    Compute the masked BLEU score for a batch of sentences.\n",
        "\n",
        "    Args:\n",
        "        label: Target label tensor.\n",
        "        pred: Predicted tensor.\n",
        "        max_n: Maximum n-gram for BLEU computation.\n",
        "\n",
        "    Returns:\n",
        "        Computed masked BLEU score.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size = len(references_batch)\n",
        "    total_bleu_score = 0.0\n",
        "\n",
        "    # Tokenize and compute n-grams for each candidate-reference pair in the batch\n",
        "    for i in range(batch_size):\n",
        "        references = references_batch[i]\n",
        "        candidates = candidates_batch[i]\n",
        "\n",
        "        precisions = []\n",
        "\n",
        "        for candidate, reference in zip(candidates, references):\n",
        "            candidate_tokens = candidate.split()\n",
        "            reference_tokens = reference.split()\n",
        "\n",
        "            # Calculate BLEU score for each n-gram up to max_n\n",
        "            for n in range(1, max_n + 1):\n",
        "                candidate_ngrams = [tuple(candidate_tokens[j:j + n]) for j in range(len(candidate_tokens) - n + 1)]\n",
        "                reference_ngrams = [tuple(reference_tokens[j:j + n]) for j in range(len(reference_tokens) - n + 1)]\n",
        "\n",
        "                precision_n = compute_precision(candidate_ngrams, reference_ngrams)\n",
        "                precisions.append(precision_n)\n",
        "\n",
        "        # Calculate the geometric mean of all the n-gram precisions for this candidate-reference pair\n",
        "        geometric_mean = np.exp(np.mean(np.log(np.maximum(precisions, 1e-10))))\n",
        "\n",
        "        # Calculate the brevity penalty for this candidate-reference pair\n",
        "        reference_length = [len(reference.split()) for reference in references]\n",
        "        candidate_length = [len(candidate.split()) for candidate in candidates]\n",
        "\n",
        "        closest_refs = [min(reference_length, key=lambda x: abs(x - candidate_len)) for candidate_len in candidate_length]\n",
        "        brevity_penalty = np.minimum(np.exp(1 - np.array(closest_refs) / np.array(candidate_length)), 1.0)\n",
        "\n",
        "        # Calculate the BLEU score for this candidate-reference pair\n",
        "        bleu_score = geometric_mean * brevity_penalty\n",
        "\n",
        "        total_bleu_score += bleu_score\n",
        "\n",
        "    # Calculate the average BLEU score over the entire batch\n",
        "    average_bleu_score = total_bleu_score / batch_size\n",
        "\n",
        "    return average_bleu_score\n",
        "\n",
        "# Example usage with batch of sentences\n",
        "references_batch = [[\"the quick brown fox jumped over the lazy dog\"]]\n",
        "candidates_batch = [[\"the quick brown fox jumped over the lazy dog from space\"]]\n",
        "bleu_score_batch = compute_bleu_batch(references_batch, candidates_batch)\n",
        "print(\"Average BLEU Score:\", bleu_score_batch)  # Output: 0.78"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Callbacks"
      ],
      "metadata": {
        "id": "NXQpZ4dIxz54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class TransformerCallbacks(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Custom callback to monitor the validation loss during training and save the best model.\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing hyperparameters.\n",
        "\n",
        "    Attributes:\n",
        "        checkpoint_filepath: Filepath to save the best model.\n",
        "        patience: Number of epochs to wait for improvement in validation loss.\n",
        "        best_loss: Best validation loss observed during training.\n",
        "\n",
        "    Methods:\n",
        "        on_epoch_end: Called at the end of each epoch to monitor the validation loss.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(TransformerCallbacks, self).__init__()\n",
        "        self.checkpoint_filepath = config.checkpoint_filepath\n",
        "        self.patience = config.patience\n",
        "        self.best_loss = float('inf')  # Initialize with a very large value for the first comparison\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \"\"\"\n",
        "        Callback function called at the end of each epoch to monitor the validation loss.\n",
        "\n",
        "        Args:\n",
        "            epoch: The current epoch number.\n",
        "            logs: Dictionary containing training and validation metrics.\n",
        "\n",
        "        \"\"\"\n",
        "        # Access the validation loss from the logs dictionary\n",
        "        val_loss = logs.get('val_loss')\n",
        "\n",
        "        if val_loss < self.best_loss:\n",
        "            self.best_loss = val_loss\n",
        "            self.model.save(self.checkpoint_filepath)\n",
        "            print('The best model has been saved at epoch #{}'.format(epoch))\n",
        "        elif self.patience:\n",
        "            self.patience -= 1\n",
        "            if self.patience == 0:\n",
        "                self.model.stop_training = True\n",
        "                print('Training stopped. No improvement after {} epochs.'.format(epoch))"
      ],
      "metadata": {
        "id": "3cdlgCwCx4aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Configuration"
      ],
      "metadata": {
        "id": "kcnL8SixyLzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Configuration class for transformer model hyperparameters.\n",
        "\n",
        "        Attributes:\n",
        "            sequence_length: Maximum sequence length for input sequences.\n",
        "            hidden_size: Hidden size for the transformer model.\n",
        "            frequency_factor: Frequency factor for positional encodings.\n",
        "            source_vocab_size: Vocabulary size for the source language.\n",
        "            target_vocab_size: Vocabulary size for the target language.\n",
        "            positional_information_type: Type of positional embeddings to use.\n",
        "            hidden_dropout_prob: Dropout probability for the hidden layers.\n",
        "            num_heads: Number of attention heads in multi-head attention.\n",
        "            intermediate_fc_size: Size of the intermediate fully connected layer.\n",
        "            warmup_steps: Number of warm-up steps for learning rate scheduling.\n",
        "            num_blocks: Number of encoder and decoder blocks in the transformer.\n",
        "            final_dropout_prob: Dropout probability for the final output.\n",
        "            epochs: Number of epochs for training.\n",
        "            checkpoint_filepath: Filepath for saving model checkpoints.\n",
        "            patience: Number of epochs with no improvement after which training will be stopped.\n",
        "\n",
        "        \"\"\"\n",
        "        self.sequence_length = 60\n",
        "        self.hidden_size = 256\n",
        "        self.frequency_factor = 10000\n",
        "        self.source_vocab_size = 16721\n",
        "        self.target_vocab_size = 31405\n",
        "        self.positional_information_type = 'embs'\n",
        "        self.hidden_dropout_prob = 0.1\n",
        "        self.num_heads = 4\n",
        "        self.intermediate_fc_size = self.hidden_size * 4\n",
        "        self.warmup_steps = 4000\n",
        "        self.num_blocks = 2\n",
        "        self.final_dropout_prob = 0.5\n",
        "        self.epochs = 30\n",
        "        self.checkpoint_filepath = '/content/drive/MyDrive/Colab Notebooks/NMT/tmp/checkpoint'\n",
        "        self.patience = 3"
      ],
      "metadata": {
        "id": "WoAROC-LyODs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor"
      ],
      "metadata": {
        "id": "ap8JYDGJ80p1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1N6EMojzGIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10539806-102f-41c5-d458-5aad2f718295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 6.0016 - masked_accuracy: 0.3204"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, embedding_19_layer_call_fn, embedding_19_layer_call_and_return_conditional_losses, positional_embeddings_21_layer_call_fn, positional_embeddings_21_layer_call_and_return_conditional_losses while saving (showing 5 of 297). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model has been saved at epoch #0\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 536s 266ms/step - loss: 6.0016 - masked_accuracy: 0.3204 - val_loss: 4.3211 - val_masked_accuracy: 0.4816\n",
            "Epoch 2/30\n",
            " 972/1828 [==============>...............] - ETA: 2:43 - loss: 4.3010 - masked_accuracy: 0.5027"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create the Transformer model\n",
        "transformer = Transformer(config, config.source_vocab_size, config.target_vocab_size)\n",
        "\n",
        "# Create the learning rate schedule\n",
        "lr = LrSchedule(config.hidden_size, config.warmup_steps)\n",
        "\n",
        "# Create the custom callbacks for monitoring and early stopping\n",
        "callbacks = TransformerCallbacks(config)\n",
        "\n",
        "# Create the Adam optimizer with the custom learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    lr,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.98,\n",
        "    epsilon=1e-9\n",
        ")\n",
        "\n",
        "# Compile the Transformer model with the custom loss function and optimizer\n",
        "transformer.compile(\n",
        "    loss=cce_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy]\n",
        ")\n",
        "\n",
        "# Train the Transformer model on the training dataset\n",
        "# and validate it on the validation dataset\n",
        "history = transformer.fit(\n",
        "    train_ds,\n",
        "    epochs=config.epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBHC8xcOLIj6"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()\n",
        "\n",
        "with open(\"vectorize.pickle\", \"rb\") as fp:\n",
        "    data = pickle.load(fp)\n",
        "\n",
        "test_pairs = data[\"test\"]\n",
        "eng_vectorizer = tf.keras.layers.TextVectorization.from_config(data[\"engvec_config\"])\n",
        "eng_vectorizer.set_weights(data[\"engvec_weights\"])\n",
        "fra_vectorizer = tf.keras.layers.TextVectorization.from_config(data[\"fravec_config\"])\n",
        "fra_vectorizer.set_weights(data[\"fravec_weights\"])\n",
        "\n",
        "# Load the trained model\n",
        "custom_objects = {\n",
        "    \"LrSchedule\": LrSchedule,\n",
        "    \"PositionalEmbeddings\": PositionalEmbeddings,\n",
        "    \"Embeddings\": Embeddings,\n",
        "    \"AttentionHead\": AttentionHead,\n",
        "    \"MultiHead_Attention\": MultiHead_Attention,\n",
        "    \"FeedForward\": FeedForward,\n",
        "    \"Encoder\": Encoder,\n",
        "    \"Decoder\": Decoder,\n",
        "    \"Transformer\": Transformer,\n",
        "    \"cce_loss\": cce_loss,\n",
        "    \"masked_accuracy\": masked_accuracy}\n",
        "\n",
        "with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/NMT/tmp/checkpoint')\n",
        "\n",
        "def translate(sentence, sequence_length, target_vocab_size):\n",
        "    \"\"\"\n",
        "    Generate the translated sentence using the trained Transformer model.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The input English sentence to be translated.\n",
        "        sequence_length (int): Maximum sequence length for input sequences.\n",
        "        target_vocab_size (int): Vocabulary size for the target language.\n",
        "\n",
        "    Returns:\n",
        "        list: A list containing the translated words in the target language.\n",
        "\n",
        "    \"\"\"\n",
        "    enc_tokens = eng_vectorizer([sentence])\n",
        "    lookup = list(fra_vectorizer.get_vocabulary())\n",
        "    start_sentinel, end_sentinel = \"[start]\", \"[end]\"\n",
        "    output_sentence = [start_sentinel]\n",
        "\n",
        "    # Generate the translated sentence word by word\n",
        "    for i in range(sequence_length):\n",
        "        vector = fra_vectorizer([\" \".join(output_sentence)])\n",
        "        assert vector.shape == (1, sequence_length + 1)\n",
        "        dec_tokens = vector[:, :-1]\n",
        "        assert dec_tokens.shape == (1, sequence_length)\n",
        "        pred = model({\"encoder_inputs\": enc_tokens, \"decoder_inputs\": dec_tokens}, training=False)\n",
        "        assert pred.shape == (1, sequence_length, target_vocab_size)\n",
        "        word = lookup[np.argmax(pred[0, i, :])]\n",
        "        output_sentence.append(word)\n",
        "        if word == end_sentinel:\n",
        "            break\n",
        "\n",
        "    return output_sentence"
      ],
      "metadata": {
        "id": "BlDQ9D04upTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuNyjrF9LK58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c5c9fc-ccff-4a7b-a807-7ff0c4bf3bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 0:\n",
            "What did you go there for ?\n",
            "== [start] Pour quelle raison y as-tu été  ?  [end]\n",
            "-> [start] [end]\n",
            "\n",
            "Test 1:\n",
            "That bicycle is too small for you .\n",
            "== [start] Ce vélo est trop petit pour vous . [end]\n",
            "-> [start] [end]\n",
            "\n",
            "Test 2:\n",
            "Are you mentally ill ?\n",
            "== [start] Êtes-vous mentalement dérangé  ?  [end]\n",
            "-> [start] [end]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_count = 3\n",
        "for n in range(test_count):\n",
        "    english_sentence, french_sentence = random.choice(test_pairs)\n",
        "    translated = translate(english_sentence)\n",
        "    print(f\"Test {n}:\")\n",
        "    print(f\"Source sentence:{english_sentence}\")\n",
        "    print(f\"Typical translation: {french_sentence}\")\n",
        "    print(f\"Model translation {' '.join(translated)}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "6sdTvZlCA7YX",
        "-ZkBwvWnIHrz",
        "plQuKWBfJas8",
        "ks43_OTo3z_b"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}