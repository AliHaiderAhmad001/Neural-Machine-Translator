# -*- coding: utf-8 -*-
"""translate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iAjbOC_0Y8t2SafAmfKp29Dkrn-7T56q
"""

# translate.py

import numpy as np
from model import load_model
from vectorizer import load_vectorizers

def translate(sentence, sequence_length, target_vocab_size):
    """
    Generate the translated sentence using the trained Transformer model.

    Args:
        sentence (str): The input English sentence to be translated.
        sequence_length (int): Maximum sequence length for input sequences.
        target_vocab_size (int): Vocabulary size for the target language.

    Returns:
        list: A list containing the translated words in the target language.

    """
    model = load_model()
    eng_vectorizer, fra_vectorizer = load_vectorizers()
    enc_tokens = eng_vectorizer([sentence])
    lookup = list(fra_vectorizer.get_vocabulary())
    start_sentinel, end_sentinel = "[start]", "[end]"
    output_sentence = [start_sentinel]

    # Generate the translated sentence word by word
    for i in range(sequence_length):
        vector = fra_vectorizer([" ".join(output_sentence)])
        assert vector.shape == (1, sequence_length + 1)
        dec_tokens = vector[:, :-1]
        assert dec_tokens.shape == (1, sequence_length)
        pred = model({"encoder_inputs": enc_tokens, "decoder_inputs": dec_tokens}, training=False)
        assert pred.shape == (1, sequence_length, target_vocab_size)
        word = lookup[np.argmax(pred[0, i, :])]
        output_sentence.append(word)
        if word == end_sentinel:
            break

    return output_sentence